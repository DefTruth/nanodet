# nanodet-swin-t_640
save_dir: workspace/nanodet-swin-t_640
model:
  arch:
    name: OneStageDetector
    backbone:
      name: MMDetectionBackbone
      type: SwinTransformer
      embed_dims: 96
      depths: [2, 2, 6, 2]
      num_heads: [3, 6, 12, 24]
      window_size: 7
      mlp_ratio: 4
      qkv_bias: True
      qk_scale: null
      drop_rate: 0.
      attn_drop_rate: 0.
      drop_path_rate: 0.2
      patch_norm: True
      out_indices: [1, 2, 3]
      with_cp: False
      convert_weights: True
      init_cfg:
        type: Pretrained
        checkpoint: https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth
    fpn:
      name: PAN
      in_channels: [192, 384, 768]
      out_channels: 256
      start_level: 0
      num_outs: 3
    head:
      name: NanoDetHead
      num_classes: 80
      conv_type: Conv
      input_channel: 256
      feat_channels: 256
      stacked_convs: 4
      activation: ReLU
      share_cls_reg: True
      octave_base_scale: 8
      scales_per_octave: 1
      strides: [8, 16, 32]
      reg_max: 10
      norm_cfg:
        type: BN
      loss:
        loss_qfl:
          name: QualityFocalLoss
          use_sigmoid: True
          beta: 2.0
          loss_weight: 1.0
        loss_dfl:
          name: DistributionFocalLoss
          loss_weight: 0.25
        loss_bbox:
          name: GIoULoss
          loss_weight: 2.0
data:
  train:
    name: CocoDataset
    img_path: data/coco/train2017
    ann_path: data/coco/annotations/instances_train2017.json
    input_size: [640,640] #[w,h]
    multi_scale: [0.6, 1.4]
    keep_ratio: True
    pipeline:
      perspective: 0.0
      scale: [1, 1]
      stretch: [[1, 1], [1, 1]]
      rotation: 0
      shear: 0
      translate: 0
      flip: 0.5
      brightness: 0.2
      contrast: [0.6, 1.4]
      saturation: [0.5, 1.2]
      normalize: [[103.53, 116.28, 123.675], [57.375, 57.12, 58.395]]
  val:
    name: CocoDataset
    img_path: data/coco/val2017
    ann_path: data/coco/annotations/instances_val2017.json
    input_size: [640,640] #[w,h]
    keep_ratio: True
    pipeline:
      normalize: [[103.53, 116.28, 123.675], [57.375, 57.12, 58.395]]
device:
  gpu_ids: [0,1,2,3,4,5,6,7]
  workers_per_gpu: 10
  batchsize_per_gpu: 8
schedule:
  resume:
#  load_model: YOUR_MODEL_PATH
  optimizer:
    name: AdamW
    lr: 0.0001
    weight_decay: 0.05
  warmup:
    name: linear
    steps: 500
    ratio: 0.01
  total_epochs: 300
  lr_schedule:
    name: MultiStepLR
    milestones: [260,280,290,295]
    gamma: 0.1
  val_intervals: 10
evaluator:
  name: CocoDetectionEvaluator
  save_key: mAP

log:
  interval: 10

class_names: ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',
              'train', 'truck', 'boat', 'traffic_light', 'fire_hydrant',
              'stop_sign', 'parking_meter', 'bench', 'bird', 'cat', 'dog',
              'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe',
              'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',
              'skis', 'snowboard', 'sports_ball', 'kite', 'baseball_bat',
              'baseball_glove', 'skateboard', 'surfboard', 'tennis_racket',
              'bottle', 'wine_glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',
              'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot',
              'hot_dog', 'pizza', 'donut', 'cake', 'chair', 'couch',
              'potted_plant', 'bed', 'dining_table', 'toilet', 'tv', 'laptop',
              'mouse', 'remote', 'keyboard', 'cell_phone', 'microwave',
              'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock',
              'vase', 'scissors', 'teddy_bear', 'hair_drier', 'toothbrush']
